## 召回模型

**ItemCF的原理？如何计算物品之间的相似度？如何计算用户对物品的兴趣分数？**

某用户喜欢物品1，物品1和物品2相似，则该用户很可能喜欢物品2。
ItemCF不直接分析用户之间的相似性，而是关注物品之间的相似性。如果多个用户同时喜欢物品 A 和物品 B，那么物品 A 和 B 被认为是相似的。首先构建用户-物品的行为矩阵R（共现矩阵），其元素为用户对物品的行为（如评分、点击、购买等）。计算R转置矩阵乘R得到物品之间的相似度得到矩阵。
用户对某物品的兴趣=用户对其他若干物品的评分x若干物品与该物品的相似度，对若干物品求和。

**ItemCF完整的召回流程**

离线计算：建立用户→物品的索引，得到用户近期感兴趣的物品评分，以及物品→物品的索引，得到物品间的相似度。

线上召回：给定用户id，找到该用户近期感兴趣的last-n物品，每个物品找到top-k相似的物品，得到一共nk个相似物品，根据公式预估每个物品的兴趣分数，返回分数最高的若干物品作为结果。

**Swing模型的作用？利用Swing如何改写ItemCF相似度公式？**

Swing模型是为了降低小圈子的权重，防止物品的重合用户是来自同一小圈子对计算带来误差。

设：

- $V_{ij} $：同时对物品 $i$ 和 $j$有行为的用户集合；
- 对于任意两个用户 $u_1, u_2 \in V_{ij}$，设 $J_1$ 和 $J_2$ 分别表示他们各自交互过的物品集合。
- 定义这两个用户的兴趣重合度为：

$$
\text{overlap}(u_1, u_2) = |J_1 \cap J_2|
$$

则相似度计算公式为：

$$
\text{sim}(i, j) = \sum_{u_1 \in V_{ij}} \sum_{u_2 \in V_{ij}, u_2 \ne u_1} \frac{1}{1 + \text{overlap}(u_1, u_2)}
$$

## 排序模型

### DIN

**DIN模型的基本思想？实现目标？**

- **DIN中的attention和Transformer中的attention有什么不同？**

Transformer中的attention采用缩放点积注意力，是一种固定的注意力函数形式，通过计算Q和K的点积再进行softmax的得到注意力权重，而在DIN中，注意力机制是一种可学习的非线性函数，先拼接候选物品embedding，用户行为序列中每个商品embedding以及二者元素积之后的向量，输入到一个MLP中由MLP计算注意力权重。

**DIN模型的缺点？SIM做了什么改进**
